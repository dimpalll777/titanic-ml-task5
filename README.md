# ğŸ›³ï¸ Titanic - Decision Trees & Random Forest (Task 5)

This project is part of an AI & ML Internship focused on tree-based models using the Titanic dataset.

## âœ… Objectives
- Train & visualize a Decision Tree
- Analyze overfitting and tree depth
- Train a Random Forest & compare results
- Interpret feature importance

## ğŸ§  Tools & Concepts
- Python, Scikit-learn, Pandas, Matplotlib
- Decision Trees, Random Forests, Feature Importance

## ğŸ“ Files
- `Titanic-Dataset (3).csv` â€“ dataset  
- `task5_code.py` â€“ Python code  
- `Titanic_Task5_Completed.pdf` â€“ report  
- `README.md` â€“ this file

## ğŸ“Š Results
- **Decision Tree Accuracy**: ~78%  
- **Random Forest Accuracy**: ~82%

---

## ğŸ“Œ Extended Description (Optional)

This project explores supervised machine learning using tree-based classification models. Using the Titanic dataset, we preprocess the data, handle missing values, encode categorical features, and apply two models:

1. **Decision Tree Classifier** â€“ to understand simple, interpretable model structure.
2. **Random Forest Classifier** â€“ to improve accuracy through ensemble learning and reduce overfitting.

The project demonstrates core ML concepts including:
- Overfitting control using tree depth
- Feature importance ranking
- Model evaluation using accuracy and classification reports

Useful for beginners learning how to apply tree algorithms on real-world datasets.
