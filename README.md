# 🛳️ Titanic - Decision Trees & Random Forest (Task 5)

This project is part of an AI & ML Internship focused on tree-based models using the Titanic dataset.

## ✅ Objectives
- Train & visualize a Decision Tree
- Analyze overfitting and tree depth
- Train a Random Forest & compare results
- Interpret feature importance

## 🧠 Tools & Concepts
- Python, Scikit-learn, Pandas, Matplotlib
- Decision Trees, Random Forests, Feature Importance

## 📁 Files
- `Titanic-Dataset (3).csv` – dataset  
- `task5_code.py` – Python code  
- `Titanic_Task5_Completed.pdf` – report  
- `README.md` – this file

## 📊 Results
- **Decision Tree Accuracy**: ~78%  
- **Random Forest Accuracy**: ~82%

---

## 📌 Extended Description (Optional)

This project explores supervised machine learning using tree-based classification models. Using the Titanic dataset, we preprocess the data, handle missing values, encode categorical features, and apply two models:

1. **Decision Tree Classifier** – to understand simple, interpretable model structure.
2. **Random Forest Classifier** – to improve accuracy through ensemble learning and reduce overfitting.

The project demonstrates core ML concepts including:
- Overfitting control using tree depth
- Feature importance ranking
- Model evaluation using accuracy and classification reports

Useful for beginners learning how to apply tree algorithms on real-world datasets.
